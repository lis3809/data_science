{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тема 2.1 Введение в ML. Основные задачи, виды классических моделей, метрики качества моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Обучение первой модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Характеристики набора данных_:\n",
    "\n",
    "- **Количество экземпляров**: 150 (по 50 в каждом из трех классов)\n",
    "\n",
    "- **Количество атрибутов**: 4 числовых, прогнозных атрибута и класс\n",
    "\n",
    "- **Информация об атрибутах**:\n",
    "\n",
    "    - длина чашелистика (sepal) в см\n",
    "    - ширина чашелистика (petal) в см\n",
    "    - длина лепестка в см\n",
    "    - ширина лепестка в см\n",
    "    - класс:\n",
    "        - Ирис-Сетоса (setosa)\n",
    "        - Ирис-разноцветный (versicolor)\n",
    "        - Ирис-Вирджиния (virginica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_iris(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in df['target'].unique():\n",
    "    print(f'==Class {t}==')\n",
    "    display(df.query(f'target == {t}').describe().loc[['min', 'mean', 'max'], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 1.1\n",
    "Многие библиотеки машинного обучения требуют, чтобы признаки были сохранены в отдельных переменных.  \n",
    "Объявите две переменные: \n",
    "- features — запишите в неё признаки;\n",
    "- target — целевой признак.  \n",
    "\n",
    "Выведите на экран размеры этих переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['target'], axis=1)\n",
    "target = df['target']\n",
    "\n",
    "print(features.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 1.2.\n",
    "Начнем с обучать модель. Попробуем предсказать результат с помощью дерева. Чтобы запустить обучение, вызовите метод fit() и передайте ему как параметр данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(features, target)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 1.3.\n",
    "Теперь в переменной model полноценная модель.   \n",
    "Создайте три новых объекта и посмотрите на результаты предсказаний.   \n",
    "Чтобы предсказать ответы, нужно вызвать метод predict() и передать ему таблицу с признаками новых объектов.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# взяли средние значения признаков для каждого из трех классов\n",
    "new_features = pd.DataFrame(\n",
    "    [[5.00600, 3.428000, 1.462000, 0.246000],\n",
    "     [5.936000, 2.770000, 4.260000, 1.326000],\n",
    "     [6.58800, 2.974000, 5.552000, 2.02600]],\n",
    "    columns=features.columns)\n",
    "\n",
    "answers = model.predict(new_features) \n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 1.4.\n",
    "Изучите правила, сформированные моделью и оцените их адекватность.  \n",
    "Правила можно посмотреть, визуализировав дерево с помощью встроенной функции plot_tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12, 6])\n",
    "tree.plot_tree(model, feature_names=features.columns);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итог**\n",
    "- познакомились с библиотекой scikit learn, и научились доставать из нее нужные модели и данные\n",
    "- научились делить датасет на фичи и целевой признак\n",
    "- научились обучать модель и получать с помощью нее предсказания\n",
    "- попробовали интерпретировать правила, сформированные обученной моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Оцениваем качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжаем использовать датасет из предыдущего блока и решать задачу предсказания класса ириса по его параметрам.  \n",
    "Научимся оценивать качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 2.1.\n",
    "\n",
    "Поделите входные данные на обучающую и тестовую части в соотношении 70/30.  \n",
    "Оцените равномерность деления, сравнив распределение по классам в выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_val, target_train, target_val = train_test_split(features, target, test_size=0.3, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_val.value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 2.2  \n",
    "Обучите модель на тренировочной части датасета.  \n",
    "Постройте прогноз для тестовой части датасета.  \n",
    "Посчитайте количество ошибочно расставленных лейблов. Для этого реализуйте функцию, которая:\n",
    " - склеит реальные лейблы с прогнозными (zip)\n",
    " - в цикле расставит 1 для элементов, у которых лейблы не совпали и 0 для остальных\n",
    " - сосчитает сумму единиц, то есть количесто элементов, для которых лейбл выставлен ошибочно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(features_train, target_train)\n",
    "predictions_val = model.predict(features_val)\n",
    "\n",
    "def count_errors(true_answers, pred_answers):\n",
    "    all_answers_together = zip(true_answers, pred_answers)\n",
    "    errors_list = [1 if v[0] != v[1] else 0 for v in all_answers_together]\n",
    "    return sum(errors_list)\n",
    "\n",
    "print(\"Ошибок:\", count_errors(target_val, predictions_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 2.3  \n",
    "Рассчитайте значение метрики accuracy для обученной модели на тестовых данных.\n",
    "Для этого реализуйте функцию, которая будет похожа на функцию, рассчитывающую количество ошибок, но вместо количества неправильных ответов, она будет возвращать долю правильных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(true_answers, pred_answers):\n",
    "    all_answers_together = zip(true_answers, pred_answers)\n",
    "    correct_answers_list = [1 if v[0] == v[1] else 0 for v in all_answers_together]\n",
    "    return sum(correct_answers_list) / len(correct_answers_list)\n",
    "\n",
    "print(\"Accuracy:\", accuracy(target_val, predictions_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 2.4\n",
    "Рассчитайте значение метрики accuracy с помощью библиотечной функции. Сравните результат с результатом, полученным с помощью собственной функции. А также сравните значение метрик для прогнозов на тестовой выборе и на обучающей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy test built-in:\", accuracy_score(target_val, predictions_val))\n",
    "\n",
    "predictions_train = model.predict(features_train)\n",
    "print(\"Accuracy train built-in:\", accuracy_score(target_train, predictions_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача 2.5\n",
    "Составьте матрицу ошибок и выведите ее.  \n",
    "Рассчитайте точность и покрытие прогноза класса \"2\" (virginica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(target_val, predictions_val), display_labels=['setosa', 'versicolor', 'virginica']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginica_tp = 13\n",
    "virginica_true_total = 15\n",
    "virginica_prediction_total = 13\n",
    "virginica_precision = virginica_tp / virginica_prediction_total\n",
    "virginica_recall = virginica_tp / virginica_true_total\n",
    "print('Virginica precision', virginica_precision)\n",
    "print('Virginica recall', virginica_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итог**\n",
    "- научились выделять валидационную часть из данных\n",
    "- научились импортировать библиотечные метрики \n",
    "- разобрались в устройстве некоторых метрик, реализовали их\n",
    "- научились интерпретировать метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "87827ea2eb5520c169a7fec310117dd7954aa84e84b54bf706c8e949532c638c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
